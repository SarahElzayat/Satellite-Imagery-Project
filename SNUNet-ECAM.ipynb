{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8278923,"sourceType":"datasetVersion","datasetId":4916411}],"dockerImageVersionId":30699,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# IMPORTS\nimport os\nimport numpy as np\nimport cv2\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_fscore_support as prfs\nimport skimage.io as io\nfrom collections import defaultdict\n\n# UNet imports\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms, models\nfrom torch.nn.functional import relu\n\nfrom torch.autograd import Variable\n\n# Custom imports\n# from utilities import *\n\n# tany\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.utils.data\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\n\nfrom tqdm import tqdm\nimport random\nimport logging\nimport datetime\nfrom tensorboardX import SummaryWriter\n# import metrics\nimport gc\n","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:20:58.056606Z","iopub.execute_input":"2024-05-14T18:20:58.056992Z","iopub.status.idle":"2024-05-14T18:21:15.649695Z","shell.execute_reply.started":"2024-05-14T18:20:58.056961Z","shell.execute_reply":"2024-05-14T18:21:15.648735Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# initialize cuda\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:21:15.651508Z","iopub.execute_input":"2024-05-14T18:21:15.652208Z","iopub.status.idle":"2024-05-14T18:21:15.714915Z","shell.execute_reply.started":"2024-05-14T18:21:15.652179Z","shell.execute_reply":"2024-05-14T18:21:15.714008Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"## ***Deep Learning Methods***\n\n1. UNet\n2. Siamese\n3. SUNet","metadata":{}},{"cell_type":"markdown","source":"### **UNet**","metadata":{}},{"cell_type":"markdown","source":"UNet Architecture\n1. Encoder (Contracting Path): down sampling the input image size while depth increases\n\n    Each Block:\n    - Two 3*3 Convolutional Layers zero-padded with stride=1 Each Followed by a RELU Activation\n    - Max Pooling Layer 2*2 with stride=2 (Dimension halved)(Same Depth) [‚¨á Down Sampling] \n\n2. Decoder","metadata":{}},{"cell_type":"markdown","source":"### **Siamese UNet**","metadata":{}},{"cell_type":"markdown","source":"1. Load the dataset using dataloaders","metadata":{}},{"cell_type":"code","source":"class LoadDataset(Dataset):\n    def __init__(self, input_folder, transforms_list=[]):\n        \n        self.before_folder = os.path.join(input_folder, 'A')\n        self.after_folder = os.path.join(input_folder, 'B')\n        self.label_folder = os.path.join(input_folder, 'label')\n\n        self.file_names = os.listdir(self.before_folder) # any folder msh far2a\n\n        self.transforms = transforms_list\n        \n    def __len__(self):\n        return len(self.file_names)\n\n    def __getitem__(self, idx):\n        before_image = io.imread(os.path.join(self.before_folder, self.file_names[idx]))\n        after_image = io.imread(os.path.join(self.before_folder, self.file_names[idx]))\n        label = io.imread(os.path.join(self.label_folder, self.file_names[idx]))\n\n        \n        label = label.astype('float32')  # Convert to floating point to allow division\n        label = label > 0\n        label = label.astype(np.int64)\n        label = torch.as_tensor(label, dtype=torch.float32)\n        label = label.squeeze()\n\n        if len(self.transforms) == 2:\n            before_image = self.transforms[0](before_image)\n            after_image = self.transforms[1](after_image)\n\n\n        return {'images': (before_image, after_image), 'label': label}\n    \n# Define the transformations\ntransform = [transforms.Compose([transforms.ToTensor()]), transforms.Compose([transforms.ToTensor()])]\n\n# Load the dataset\ndataset = LoadDataset('/kaggle/input/sat-dataset/trainval', transform)\n\n# Split the dataset into training, test, and validation sets (80, 10, 10)\ntrain_set, test_set = train_test_split(dataset, test_size=0.2, random_state=42)\n# val_set, test_set = train_test_split(temp_set, test_size=0.5, random_state=42)\n\n# create the DataLoader\ndataloader = {\n    'train': DataLoader(train_set, batch_size=16, shuffle=True),\n#     'val': DataLoader(val_set, batch_size=16, shuffle=False),\n    'test': DataLoader(test_set, batch_size=16, shuffle=False)\n}\n\nprint(\"DATASET LOADED\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:21:15.716354Z","iopub.execute_input":"2024-05-14T18:21:15.716658Z","iopub.status.idle":"2024-05-14T18:22:49.089672Z","shell.execute_reply.started":"2024-05-14T18:21:15.716634Z","shell.execute_reply":"2024-05-14T18:22:49.088540Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"DATASET LOADED\n","output_type":"stream"}]},{"cell_type":"markdown","source":"2. Build the Siamese model\n\n<img src=\"siamese_architecture.jpg\"/>\n","metadata":{}},{"cell_type":"markdown","source":"3. Train the model","metadata":{}},{"cell_type":"markdown","source":"4. Test the model","metadata":{}},{"cell_type":"code","source":"# class FocalLoss(nn.Module):\n#     def __init__(self, gamma=0, alpha=None, size_average=True):\n#         super(FocalLoss, self).__init__()\n#         self.gamma = gamma\n#         self.alpha = alpha\n#         if isinstance(alpha, (float, int)):\n#             self.alpha = torch.Tensor([alpha, 1-alpha])\n#         if isinstance(alpha, list):\n#             self.alpha = torch.Tensor(alpha)\n#         self.size_average = size_average\n\n#     def forward(self, input, target):\n#         if input.dim() > 2:\n#             # N, C, H, W => N, H*W, C\n#             input = input.view(input.size(0), input.size(1), -1).transpose(1, 2).contiguous()\n#             # N, H*W, C => N*H*W, C\n#             input = input.view(-1, input.size(2))\n#         else:\n#             input = input.contiguous().view(-1, input.size(1))\n\n\n#         target = target.view(-1, 1)\n#         logpt = F.log_softmax(input)\n#         logpt = logpt.gather(1, target)\n#         logpt = logpt.view(-1)\n#         pt = Variable(logpt.data.exp())\n\n#         if self.alpha is not None:\n#             if self.alpha.type() != input.data.type():\n#                 self.alpha = self.alpha.type_as(input.data)\n#             at = self.alpha.gather(0, target.data.view(-1))\n#             logpt = logpt * Variable(at)\n\n#         loss = -1 * (1-pt)**self.gamma * logpt\n\n#         if self.size_average:\n#             return loss.mean()\n#         else:\n#             return loss.sum()\n\n# # def dice_loss(logits, true, device, eps=1e-7):\n# #     \"\"\"Computes the S√∏rensen‚ÄìDice loss.\n# #     Note that PyTorch optimizers minimize a loss. In this\n# #     case, we would like to maximize the dice loss so we\n# #     return the negated dice loss.\n# #     Args:\n# #         true: a tensor of shape [B, 1, H, W].\n# #         logits: a tensor of shape [B, C, H, W]. Corresponds to\n# #             the raw output or logits of the model.\n# #         eps: added to the denominator for numerical stability.\n# #     Returns:\n# #         dice_loss: the S√∏rensen‚ÄìDice loss.\n# #     \"\"\"\n# #     num_classes = logits.shape[1]\n# #     if num_classes == 1:\n# #         true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n# #         true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n# #         true_1_hot_f = true_1_hot[:, 0:1, :, :]\n# #         true_1_hot_s = true_1_hot[:, 1:2, :, :]\n# #         true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n# #         pos_prob = torch.sigmoid(logits)\n# #         neg_prob = 1 - pos_prob\n# #         probas = torch.cat([pos_prob, neg_prob], dim=1)\n# #     else:\n# #         true_1_hot = torch.eye(num_classes, device=device)[true.squeeze(1)]\n# #         true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n# #         probas = F.softmax(logits, dim=1)\n# #     true_1_hot = true_1_hot.type(logits.type())\n# #     dims = (0,) + tuple(range(2, true.ndimension()))\n# #     intersection = torch.sum(probas * true_1_hot, dims)\n# #     cardinality = torch.sum(probas + true_1_hot, dims)\n# #     dice_loss = (2. * intersection / (cardinality + eps)).mean()\n# #     return (1 - dice_loss)\n\n\n# # # def dice_loss(pred, target, smooth=1.):\n# # #     '''\n# # #      The Dice coefficient D between two sets ùê¥ and ùêµ is defined as:\n# # #      D= (2√ó‚à£A‚à©B‚à£)/ (‚à£A‚à£+‚à£B‚à£)\n# # #      ‚à£A‚à©B‚à£: total no of pixels in pred,gold that has +ve\n# # #     '''\n# # #     pred = pred.contiguous() # contiguous() is a method that is used to ensure that the tensor is stored in a contiguous block of memory.\n# # #     target = target.contiguous()\n    \n# # #     print(\"Predicted:\",pred)\n# # #     print(\"Target:\", target)\n    \n\n# # #     intersection = (pred * target).sum(dim=2).sum(dim=2)  # Sumation of Both Width & Height\n\n# # #     loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n\n# # #     return loss.mean()","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:22:49.092184Z","iopub.execute_input":"2024-05-14T18:22:49.092497Z","iopub.status.idle":"2024-05-14T18:22:49.100941Z","shell.execute_reply.started":"2024-05-14T18:22:49.092469Z","shell.execute_reply":"2024-05-14T18:22:49.099927Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, gamma=0, alpha=None, size_average=True):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        if isinstance(alpha, (float, int)):\n            self.alpha = torch.Tensor([alpha, 1-alpha])\n        if isinstance(alpha, list):\n            self.alpha = torch.Tensor(alpha)\n        self.size_average = size_average\n\n    def forward(self, input, target):\n        if input.dim() > 2:\n            # N,C,H,W => N,C,H*W\n            input = input.view(input.size(0), input.size(1), -1)\n\n            # N,C,H*W => N,H*W,C\n            input = input.transpose(1, 2)\n\n            # N,H*W,C => N*H*W,C\n            input = input.contiguous().view(-1, input.size(2))\n\n\n        target = target.view(-1, 1)\n        logpt = F.log_softmax(input,dim=1)\n        logpt = logpt.gather(1, target)\n        logpt = logpt.view(-1)\n        pt = Variable(logpt.data.exp())\n\n        if self.alpha is not None:\n            if self.alpha.type() != input.data.type():\n                self.alpha = self.alpha.type_as(input.data)\n            at = self.alpha.gather(0, target.data.view(-1))\n            logpt = logpt * Variable(at)\n\n        loss = -1 * (1-pt)**self.gamma * logpt\n\n        if self.size_average:\n            return loss.mean()\n        else:\n            return loss.sum()\n\ndef dice_loss(logits, true, positive_weight=1, eps=1e-7):\n    \"\"\"Computes the S√∏rensen‚ÄìDice loss with weighted positive class.\"\"\"\n    true_1_hot = torch.eye(2, device=logits.device)[true.squeeze(1)]\n    true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n    probas = F.softmax(logits, dim=1)\n    true_1_hot = true_1_hot.type(logits.type())\n\n    dims = (0,) + tuple(range(2, true.ndimension()))\n    intersection = torch.sum(probas * true_1_hot, dims)\n    cardinality = torch.sum(probas + true_1_hot, dims)\n\n    # Weighted sum of intersection and cardinality for positive class\n    weighted_intersection = intersection[:, 1] * positive_weight\n    weighted_cardinality = cardinality[:, 1] * positive_weight\n\n    dice_loss = (2. * weighted_intersection / (weighted_cardinality + eps)).mean()\n\n    return (1 - dice_loss)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:22:49.102392Z","iopub.execute_input":"2024-05-14T18:22:49.103024Z","iopub.status.idle":"2024-05-14T18:22:49.120246Z","shell.execute_reply.started":"2024-05-14T18:22:49.102991Z","shell.execute_reply":"2024-05-14T18:22:49.119419Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### **Siamese UNet ECAM**","metadata":{}},{"cell_type":"code","source":"# Model\n \n# The convolution block architecture consists of:\n# 1. Convolution layer with kernel size 3x3 and padding 1 (in_channels, mid_channel)\n# 2. Batch normalization\n# 3. ReLU activation\n# 4. Second convolution layer with kernel size 3x3 and padding 1 (mid_channel, out_channels)\n# 5. Batch normalization\n# 6. ReLU activation of the fist convolution layer with the output from second batch normalization\n\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, mid_channel, out_channels):\n        super(ConvBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, mid_channel, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(mid_channel)\n        self.conv2 = nn.Conv2d(mid_channel, out_channels, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True) # activation function (inplace modifies input directly)\n    \n    def forward(self, input):\n        input = self.conv1(input) # first convolution layer\n\n        # save the result of the first convolution for the last layer\n        x = input\n\n        input = self.bn1(input) # first batch normalization\n        input = self.relu(input) # activation function\n\n        input = self.conv2(input) # second convolution layer\n        input = self.bn2(input)\n\n        # add the result of the first convolution to the output of the second convolution\n        input += x\n        output = self.relu(input) # final activation function\n        return output\n\n\n# The channel attention module\n\nclass ChannelAttention(nn.Module):\n    def __init__(self, in_channels, ratio = 16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n        self.fc1 = nn.Conv2d(in_channels,in_channels//ratio,1,bias=False)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Conv2d(in_channels//ratio, in_channels,1,bias=False)\n        self.sigmod = nn.Sigmoid()\n\n    def forward(self,x):\n        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n        out = avg_out + max_out\n        return self.sigmod(out)\n    \n\n# cuild the model\nclass SiameseUNetECAM(nn.Module):\n    def __init__(self, input_channels, output_channels):\n        super(SiameseUNetECAM, self).__init__()\n        torch.nn.Module.dump_patches = True # enables a feature in PyTorch where any changes to the module hierarchy are tracked and patches are dumped to files.\n\n        n1 = 32     # the initial number of channels of feature map\n        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.conv0_0 = ConvBlock(input_channels, filters[0], filters[0])\n        self.conv1_0 = ConvBlock(filters[0], filters[1], filters[1])\n\n        self.Up1_0 = nn.ConvTranspose2d(filters[1], filters[1], 2, stride=2)\n\n        self.conv2_0 = ConvBlock(filters[1], filters[2], filters[2])\n\n        self.Up2_0 = nn.ConvTranspose2d(filters[2], filters[2], 2, stride=2)\n\n        self.conv3_0 = ConvBlock(filters[2], filters[3], filters[3])\n\n        self.Up3_0 = nn.ConvTranspose2d(filters[3], filters[3], 2, stride=2)\n        self.conv4_0 = ConvBlock(filters[3], filters[4], filters[4])\n\n        self.Up4_0 = nn.ConvTranspose2d(filters[4], filters[4], 2, stride=2)\n\n        self.conv0_1 = ConvBlock(filters[0] * 2 + filters[1], filters[0], filters[0])\n        self.conv1_1 = ConvBlock(filters[1] * 2 + filters[2], filters[1], filters[1])\n        self.Up1_1 = nn.ConvTranspose2d(filters[1], filters[1], 2, stride=2)\n        self.conv2_1 = ConvBlock(filters[2] * 2 + filters[3], filters[2], filters[2])\n        self.Up2_1 = nn.ConvTranspose2d(filters[2], filters[2], 2, stride=2)\n        self.conv3_1 = ConvBlock(filters[3] * 2 + filters[4], filters[3], filters[3])\n        self.Up3_1 = nn.ConvTranspose2d(filters[3], filters[3], 2, stride=2)\n\n        self.conv0_2 = ConvBlock(filters[0] * 3 + filters[1], filters[0], filters[0])\n        self.conv1_2 = ConvBlock(filters[1] * 3 + filters[2], filters[1], filters[1])\n        self.Up1_2 = nn.ConvTranspose2d(filters[1], filters[1], 2, stride=2)\n        self.conv2_2 = ConvBlock(filters[2] * 3 + filters[3], filters[2], filters[2])\n        self.Up2_2 = nn.ConvTranspose2d(filters[2], filters[2], 2, stride=2)\n\n        self.conv0_3 = ConvBlock(filters[0] * 4 + filters[1], filters[0], filters[0])\n        self.conv1_3 = ConvBlock(filters[1] * 4 + filters[2], filters[1], filters[1])\n        self.Up1_3 = nn.ConvTranspose2d(filters[1], filters[1], 2, stride=2)\n\n        self.conv0_4 = ConvBlock(filters[0] * 5 + filters[1], filters[0], filters[0])\n\n        self.ca = ChannelAttention(filters[0] * 4, ratio=16)\n        self.ca1 = ChannelAttention(filters[0], ratio=16 // 4)\n\n        self.conv_final = nn.Conv2d(filters[0] * 4, output_channels, kernel_size=1)\n\n        # msh fahma dy beta3mel eh bas mashy ba3deen\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n\n    def forward(self, xA, xB):\n        '''xA'''\n        x0_0A = self.conv0_0(xA)\n        x1_0A = self.conv1_0(self.pool(x0_0A))\n        x2_0A = self.conv2_0(self.pool(x1_0A))\n        x3_0A = self.conv3_0(self.pool(x2_0A))\n        # x4_0A = self.conv4_0(self.pool(x3_0A))\n        '''xB'''\n        x0_0B = self.conv0_0(xB)\n        x1_0B = self.conv1_0(self.pool(x0_0B))\n        x2_0B = self.conv2_0(self.pool(x1_0B))\n        x3_0B = self.conv3_0(self.pool(x2_0B))\n        x4_0B = self.conv4_0(self.pool(x3_0B))\n\n        x0_1 = self.conv0_1(torch.cat([x0_0A, x0_0B, self.Up1_0(x1_0B)], 1))\n        x1_1 = self.conv1_1(torch.cat([x1_0A, x1_0B, self.Up2_0(x2_0B)], 1))\n        x0_2 = self.conv0_2(torch.cat([x0_0A, x0_0B, x0_1, self.Up1_1(x1_1)], 1))\n\n\n        x2_1 = self.conv2_1(torch.cat([x2_0A, x2_0B, self.Up3_0(x3_0B)], 1))\n        x1_2 = self.conv1_2(torch.cat([x1_0A, x1_0B, x1_1, self.Up2_1(x2_1)], 1))\n        x0_3 = self.conv0_3(torch.cat([x0_0A, x0_0B, x0_1, x0_2, self.Up1_2(x1_2)], 1))\n\n        x3_1 = self.conv3_1(torch.cat([x3_0A, x3_0B, self.Up4_0(x4_0B)], 1))\n        x2_2 = self.conv2_2(torch.cat([x2_0A, x2_0B, x2_1, self.Up3_1(x3_1)], 1))\n        x1_3 = self.conv1_3(torch.cat([x1_0A, x1_0B, x1_1, x1_2, self.Up2_2(x2_2)], 1))\n        x0_4 = self.conv0_4(torch.cat([x0_0A, x0_0B, x0_1, x0_2, x0_3, self.Up1_3(x1_3)], 1))\n\n        output = torch.cat([x0_1, x0_2, x0_3, x0_4], 1)\n\n        intra = torch.sum(torch.stack((x0_1, x0_2, x0_3, x0_4)), dim=0)\n        ca1 = self.ca1(intra)\n        output = self.ca(output) * (output + ca1.repeat(1, 4, 1, 1))\n        output = self.conv_final(output)\n\n        return (output, )","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:22:49.121422Z","iopub.execute_input":"2024-05-14T18:22:49.121913Z","iopub.status.idle":"2024-05-14T18:22:49.162953Z","shell.execute_reply.started":"2024-05-14T18:22:49.121877Z","shell.execute_reply":"2024-05-14T18:22:49.162155Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# some functions and definitions for training\nparameters = {\n  \"patch_size\": 256,\n  \"num_gpus\": 1,\n  \"num_workers\": 8,\n  \"num_channel\": 3,\n  \"epochs\": 1,\n  \"batch_size\": 16,\n  \"learning_rate\": 1e-3,\n  \"loss_function\": \"hybrid\",\n  \"dataset_dir\": \"./dataset/trainval/\",\n  \"weight_dir\": \"./content/\",\n  \"log_dir\": \"./log/\"\n}\n\ntrain_set = dataloader['train']\n# val_set = dataloader['val']\ntest_set = dataloader['test']\n\ndef seed_torch(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\n\ndef initialize_metrics():\n    \"\"\"Generates a dictionary of metrics with metrics as keys\n       and empty lists as values\n\n    Returns\n    -------\n    dict\n        a dictionary of metrics\n\n    \"\"\"\n    metrics = {\n        'cd_losses': [],\n        'cd_corrects': [],\n        'cd_precisions': [],\n        'cd_recalls': [],\n        'cd_f1scores': [],\n        'learning_rate': [],\n        'jaccard_scores': []\n    }\n\n    return metrics\n\ndef set_metrics(metric_dict, cd_loss, cd_corrects, cd_report, lr, jaccard_score):\n    \"\"\"Updates metric dict with batch metrics\n\n    Parameters\n    ----------\n    metric_dict : dict\n        dict of metrics\n    cd_loss : dict(?)\n        loss value\n    cd_corrects : dict(?)\n        number of correct results (to generate accuracy\n    cd_report : list\n        precision, recall, f1 values\n\n    Returns\n    -------\n    dict\n        dict of  updated metrics\n\n\n    \"\"\"\n    metric_dict['cd_losses'].append(cd_loss.item())\n    metric_dict['cd_corrects'].append(cd_corrects.item())\n    metric_dict['cd_precisions'].append(cd_report[0])\n    metric_dict['cd_recalls'].append(cd_report[1])\n    metric_dict['cd_f1scores'].append(cd_report[2])\n    metric_dict['learning_rate'].append(lr)\n    metric_dict['jaccard_scores'].append(jaccard_score)\n\n    return metric_dict\n\n\n\ndef get_mean_metrics(metric_dict):\n    \"\"\"takes a dictionary of lists for metrics and returns dict of mean values\n\n    Parameters\n    ----------\n    metric_dict : dict\n        A dictionary of metrics\n\n    Returns\n    -------\n    dict\n        dict of floats that reflect mean metric value\n\n    \"\"\"\n    return {k: np.mean(v) for k, v in metric_dict.items()}\n\n\ndef hybrid_loss(predictions, target):\n    \"\"\"Calculating the loss\"\"\"\n    loss = 0\n\n    # gamma=0, alpha=None --> CE\n    focal = FocalLoss()\n\n    for prediction in predictions:\n\n        bce = focal(prediction, target)\n        dice = dice_loss(prediction, target)\n        loss += bce + dice\n\n    return loss\n\n\ndef jaccard_index(pred, target, smooth=1.0):\n    '''\n    Jaccard Index (IoU) between two sets ùê¥ and ùêµ is defined as:\n    J(A, B) = 1 - (‚à£A‚à©B‚à£ / ‚à£A‚à™B‚à£)\n    Where:\n    ‚à£A‚à©B‚à£: Intersection of sets A and B\n    ‚à£A‚à™B‚à£: Union of sets A and B\n    '''\n    pred = pred.contiguous() \n    target = target.contiguous() \n\n    intersection = (pred * target).sum(dim=2).sum(dim=2)  \n    union = pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) - intersection\n\n    IOU = ((intersection + smooth) / (union + smooth))\n    \n    return 1- IOU.mean()\n\n\ndef calc_loss(predictions, labels, metrics, bce_weight=0.5):\n    # Binary Cress Entropy\n    # In PyTorch, binary_cross_entropy_with_logits is a loss function that combines a sigmoid activation function and binary cross-entropy loss.\n    # However, it doesn't explicitly apply the sigmoid function to the input. Instead, it expects the input to be logits, which are the raw outputs of a model without applying any activation function.\n    for prediction, label in zip(predictions, labels):\n        \n#         print(\"Prediction:\", prediction)\n#         print(\"Label:\", label)\n#         print(label.size(0))\n        \n#         print(type(label))\n#         print(type(prediction))\n        prediction = F.sigmoid(prediction)\n    \n        dice = dice_loss(prediction, label)\n\n        bce = F.binary_cross_entropy_with_logits(prediction.float(), label.float())\n\n\n        # Custom Loss function that combines bce & dice losses\n        # Binary Cross-Entropy (BCE) Loss: BCE loss aims to minimize the difference between the predicted probability distribution and the ground truth binary labels.\n        # It penalizes deviations from the true binary labels, typically encouraging the model to output probabilities that align well with the ground truth.\n        # Dice Loss: Dice loss aims to maximize the overlap between the predicted segmentation mask and the ground truth mask.\n        # It penalizes deviations from the true segmentation mask, typically encouraging the model to produce segmentations that align well with the ground truth boundaries.\n        loss = bce * bce_weight + dice * (1 - bce_weight)\n\n        jac_index=jaccard_index(prediction, label)\n\n\n        metrics['bce'] += bce.data.cpu().numpy() * label.size(0)\n        metrics['dice'] += dice.data.cpu().numpy() * label.size(0)\n        metrics['loss'] += loss.data.cpu().numpy() * label.size(0)\n        metrics['jaccrod_index']+=jac_index.data.cpu().numpy() * label.size(0)\n\n    return loss, metrics\n","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:22:49.164386Z","iopub.execute_input":"2024-05-14T18:22:49.164688Z","iopub.status.idle":"2024-05-14T18:22:49.186808Z","shell.execute_reply.started":"2024-05-14T18:22:49.164646Z","shell.execute_reply":"2024-05-14T18:22:49.185876Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def evaluate(model):\n    model.eval()\n    \n    jaccard_scores = []\n    \n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n    with torch.no_grad():\n        tbar = tqdm(test_set)\n        \n        for batch in tbar:\n            # load the data to the device\n            before_images = batch['images'][0].to(device)\n            after_images = batch['images'][1].to(device)\n            labels = batch['label'].long().to(device)\n            \n            \n            predictions = model(before_images, after_images)\n            predictions = predictions[0]\n            _, predictions = torch.max(predictions, 1)\n            \n            print(len(predictions))\n            \n            for prediction, label in zip(predictions, labels):\n                predicted = prediction.cpu().numpy().astype(np.uint8)\n                \n                ground_truth = label.cpu().numpy().astype(np.uint8)\n                \n                # calculate jaccard score\n                \n                jaccard_scores.append(jaccard_score(predicted.flatten(), ground_truth.flatten(), zero_division=1))\n            \n            del before_images, after_images, labels\n            \n        jaccard_mean = np.mean(jaccard_scores)\n            \n        print(\"Test Jaccard Mean:\", jaccard_mean)\n        \n        return jaccard_mean\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:22:49.187855Z","iopub.execute_input":"2024-05-14T18:22:49.188135Z","iopub.status.idle":"2024-05-14T18:22:49.208009Z","shell.execute_reply.started":"2024-05-14T18:22:49.188113Z","shell.execute_reply":"2024-05-14T18:22:49.206563Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# train the model\n\n\n\"\"\"\nInitialize experiments log\n\"\"\"\n# logging.basicConfig(level=logging.INFO)\n# writer = SummaryWriter(parameters['log_dir'] + f'/{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}/')\n\n\"\"\"\nSet up environment: define paths, download data, and set device\n\"\"\"\n# logging.info('GPU AVAILABLE? ' + str(torch.cuda.is_available()))\n\nseed_torch(seed=777)\n\n\n\"\"\"\nLoad Model then define other aspects of the model\n\"\"\"\n# logging.info('LOADING Model')\nmodel = SiameseUNetECAM(3, 2).to(device)\n\n# criterion = hybrid_loss # loss function bce + dice\ncriterion = hybrid_loss\noptimizer = torch.optim.AdamW(model.parameters(), lr=parameters['learning_rate']) # Be careful when you adjust learning rate, you can refer to the linear scaling rule\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.5)\n\n\"\"\"\n Set starting values\n\"\"\"\n# best_metrics = {'cd_f1scores': -1, 'cd_recalls': -1, 'cd_precisions': -1}\n# logging.info('STARTING training')\ntotal_step = -1\n\nvalidation_jacc=float('-inf')\n\n# training loop\nfor epoch in range(parameters['epochs']):\n    epoch_loss = []\n#     train_metrics = initialize_metrics()\n#     val_metrics = initialize_metrics()\n    \n#     metrics = defaultdict(float)\n\n    \"\"\"\n    Begin Training\n    \"\"\"\n    model.train()\n#     logging.info('SET model mode to train!')\n\n    batch_iteration = 0\n\n    tbar = tqdm(train_set)\n    for batch in tbar:\n        tbar.set_description(\"epoch {} info \".format(epoch) + str(batch_iteration) + \" - \" + str(batch_iteration + parameters['batch_size']))\n        batch_iteration = batch_iteration + parameters['batch_size']\n        total_step += 1\n\n        # load the data to the device\n        before_images = batch['images'][0].to(device)\n        after_images = batch['images'][1].to(device)\n        labels = batch['label'].long().to(device)\n\n        \n        # Zero the gradient\n        optimizer.zero_grad()\n\n        # Get model predictions, calculate loss, backprop\n        predictions = model(before_images, after_images)\n\n        # calculate the loss\n        cd_loss = criterion(predictions, labels)\n        loss = cd_loss\n\n        # backpropagation\n        loss.backward()\n        optimizer.step()        \n        \n        predictions = predictions[0]\n#         print(len(predictions))\n#         print(len(labels))\n        _, predictions = torch.max(predictions, 1)\n    \n        epoch_loss.append(loss.item())\n\n\n\n        \n#         print(len(predictions))\n#         print(len(labels))\n\n        # evaluation and metrics\n#         jac_score = jaccard_score(labels.data.cpu().numpy().flatten(),\n#                                 predictions.data.cpu().numpy().flatten(), \n#                                 zero_division=1)\n\n#         jac_score = metrics['jaccrod_index'] \n\n#         cd_corrects = (100 *\n#                        (predictions.squeeze().byte() == labels.squeeze().byte()).sum() /\n#                        (labels.size()[0] * (parameters['patch_size']**2)))\n\n#         cd_train_report = prfs(labels.data.cpu().numpy().flatten(),\n#                                predictions.data.cpu().numpy().flatten(),\n#                                average='binary',\n#                                zero_division=0,\n#                                pos_label=1)\n\n#         train_metrics = set_metrics(train_metrics,\n#                                     cd_loss,\n#                                     cd_corrects,\n#                                     cd_train_report,\n#                                     scheduler.get_last_lr(),\n#                                     0)\n\n        # log the batch mean metrics\n#         mean_train_metrics = get_mean_metrics(train_metrics)\n\n#         for k, v in mean_train_metrics.items():\n#             writer.add_scalars(str(k), {'train': v}, total_step)\n\n        # clear batch variables from memory\n        del before_images, after_images, labels\n    \n#     scheduler.step()\n    \n    current_loss=sum(epoch_loss)/len(epoch_loss)\n    gc.collect()\n    \n    jaccard_test = evaluate(model)\n\n    # print(\"JACCARD INDEX EVALUATION \",m_jaccard)\n#     print(\"TOTAL LOSS EVALUATION \",m_loss)\n    scheduler.step()\n    torch.save(model.state_dict(), f\"/kaggle/working/models/pretrained_epoch_{epoch_index}.pth\")\n    if validation_jacc<m_jaccard:\n\n        torch.save(model.state_dict(), f\"/kaggle/working/models/best_pretrained_post_aug_pretrained.pth\")\n        validation_jacc=m_jaccard\n\n#     logging.info(\"EPOCH {} TRAIN METRICS\".format(epoch) + str(mean_train_metrics))\n#     print(\"EPOCH {} TRAIN METRICS\".format(epoch) + str(mean_train_metrics))\n\n    print('An epoch finished.')\n    \n    \n# writer.close()  # close tensor board\nprint('Done!')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:22:49.209671Z","iopub.execute_input":"2024-05-14T18:22:49.210015Z","iopub.status.idle":"2024-05-14T18:30:52.025397Z","shell.execute_reply.started":"2024-05-14T18:22:49.209989Z","shell.execute_reply":"2024-05-14T18:30:52.023808Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"epoch 0 info 3888 - 3904: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 244/244 [06:53<00:00,  1.70s/it]\n  0%|          | 0/61 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":"  2%|‚ñè         | 1/61 [00:01<01:07,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":"  3%|‚ñé         | 2/61 [00:02<01:06,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":"  5%|‚ñç         | 3/61 [00:03<01:05,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":"  7%|‚ñã         | 4/61 [00:04<01:03,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":"  8%|‚ñä         | 5/61 [00:05<01:02,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 10%|‚ñâ         | 6/61 [00:06<01:01,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 11%|‚ñà‚ñè        | 7/61 [00:07<01:00,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 13%|‚ñà‚ñé        | 8/61 [00:08<00:59,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 15%|‚ñà‚ñç        | 9/61 [00:10<00:58,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 16%|‚ñà‚ñã        | 10/61 [00:11<00:56,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 18%|‚ñà‚ñä        | 11/61 [00:12<00:55,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 20%|‚ñà‚ñâ        | 12/61 [00:13<00:54,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 21%|‚ñà‚ñà‚ñè       | 13/61 [00:14<00:53,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 23%|‚ñà‚ñà‚ñé       | 14/61 [00:15<00:52,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 25%|‚ñà‚ñà‚ñç       | 15/61 [00:16<00:51,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 26%|‚ñà‚ñà‚ñå       | 16/61 [00:17<00:50,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 28%|‚ñà‚ñà‚ñä       | 17/61 [00:18<00:48,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 30%|‚ñà‚ñà‚ñâ       | 18/61 [00:20<00:47,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 31%|‚ñà‚ñà‚ñà       | 19/61 [00:21<00:46,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 33%|‚ñà‚ñà‚ñà‚ñé      | 20/61 [00:22<00:45,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 34%|‚ñà‚ñà‚ñà‚ñç      | 21/61 [00:23<00:44,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 36%|‚ñà‚ñà‚ñà‚ñå      | 22/61 [00:24<00:43,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 38%|‚ñà‚ñà‚ñà‚ñä      | 23/61 [00:25<00:42,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 39%|‚ñà‚ñà‚ñà‚ñâ      | 24/61 [00:26<00:41,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 41%|‚ñà‚ñà‚ñà‚ñà      | 25/61 [00:27<00:39,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 26/61 [00:28<00:38,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 27/61 [00:30<00:37,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 28/61 [00:31<00:36,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 29/61 [00:32<00:35,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 30/61 [00:33<00:34,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 31/61 [00:34<00:33,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 32/61 [00:35<00:32,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 33/61 [00:36<00:31,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 34/61 [00:37<00:30,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 35/61 [00:39<00:28,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 36/61 [00:40<00:27,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 37/61 [00:41<00:26,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 38/61 [00:42<00:25,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 39/61 [00:43<00:24,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 40/61 [00:44<00:23,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 41/61 [00:45<00:22,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 42/61 [00:46<00:21,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 43/61 [00:47<00:19,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 44/61 [00:48<00:18,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 45/61 [00:50<00:17,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 46/61 [00:51<00:16,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 47/61 [00:52<00:15,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 48/61 [00:53<00:14,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 49/61 [00:54<00:13,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 50/61 [00:55<00:12,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 51/61 [00:56<00:11,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 52/61 [00:57<00:10,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 53/61 [00:59<00:08,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 54/61 [01:00<00:07,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 55/61 [01:01<00:06,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 56/61 [01:02<00:05,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 57/61 [01:03<00:04,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 58/61 [01:04<00:03,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 59/61 [01:05<00:02,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"16\n","output_type":"stream"},{"name":"stderr","text":" 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 60/61 [01:06<00:01,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"14\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61/61 [01:07<00:00,  1.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"Test Jaccard Mean: 0.01430858270003216\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 136\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# print(\"JACCARD INDEX EVALUATION \",m_jaccard)\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#     print(\"TOTAL LOSS EVALUATION \",m_loss)\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 136\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/models/pretrained_epoch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mepoch_index\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validation_jacc\u001b[38;5;241m<\u001b[39mm_jaccard:\n\u001b[1;32m    139\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/models/best_pretrained_post_aug_pretrained.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'epoch_index' is not defined"],"ename":"NameError","evalue":"name 'epoch_index' is not defined","output_type":"error"}]}]}